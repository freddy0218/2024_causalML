{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b22b3c7-9e1f-4c1e-99d7-d362adca8e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/miniconda3/envs/ships/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nf\n",
    "from netCDF4 import Dataset\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ast,gc,pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "# Custom packages\n",
    "import read_config\n",
    "from util.data_process import read_vars, proc_dataset\n",
    "from util.models import performance_scores,train_baseline,causal_settings,train_PC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3705646-e7cf-49ad-9cc1-86706a6837a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read configuration file\n",
    "config_set = read_config.read_config()\n",
    "# Define Target\n",
    "if int(config_set['target_lag'])==4:\n",
    "    target='DELV24'\n",
    "elif int(config_set['target_lag'])==8:\n",
    "    target='DELV48'\n",
    "seeds = np.arange(100,130,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471cdea8-870d-4301-8a11-db09becbf95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 598.44it/s]\n",
      "22it [00:00, 46.47it/s]\n",
      "22it [00:00, 131.24it/s]\n",
      "22it [00:00, 167.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:41<00:00,  3.19s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 642.13it/s]\n",
      "22it [00:00, 50.45it/s]\n",
      "22it [00:00, 131.97it/s]\n",
      "22it [00:00, 168.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:30<00:00,  2.82s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 658.00it/s]\n",
      "22it [00:00, 49.47it/s]\n",
      "22it [00:00, 130.66it/s]\n",
      "22it [00:00, 170.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:23<00:00,  2.61s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 639.49it/s]\n",
      "22it [00:00, 50.69it/s]\n",
      "22it [00:00, 132.63it/s]\n",
      "22it [00:00, 170.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:23<00:00,  2.60s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 633.27it/s]\n",
      "22it [00:00, 50.72it/s]\n",
      "22it [00:00, 130.39it/s]\n",
      "22it [00:00, 169.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:03<00:00,  1.97s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 649.00it/s]\n",
      "22it [00:00, 50.26it/s]\n",
      "22it [00:00, 131.26it/s]\n",
      "22it [00:00, 169.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:17<00:00,  2.41s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 634.73it/s]\n",
      "22it [00:00, 50.67it/s]\n",
      "22it [00:00, 129.88it/s]\n",
      "22it [00:00, 163.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:23<00:00,  2.62s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 647.16it/s]\n",
      "22it [00:00, 50.47it/s]\n",
      "22it [00:00, 132.38it/s]\n",
      "22it [00:00, 167.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:33<00:00,  2.94s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 651.23it/s]\n",
      "22it [00:00, 50.24it/s]\n",
      "22it [00:00, 132.53it/s]\n",
      "22it [00:00, 171.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:30<00:00,  2.83s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 643.99it/s]\n",
      "22it [00:00, 51.19it/s]\n",
      "22it [00:00, 131.16it/s]\n",
      "22it [00:00, 166.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:27<00:00,  2.74s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 651.61it/s]\n",
      "22it [00:00, 50.04it/s]\n",
      "22it [00:00, 127.28it/s]\n",
      "22it [00:00, 165.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:11<00:00,  2.25s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 640.30it/s]\n",
      "22it [00:00, 50.40it/s]\n",
      "22it [00:00, 129.93it/s]\n",
      "22it [00:00, 164.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:19<00:00,  2.48s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 637.38it/s]\n",
      "22it [00:00, 51.25it/s]\n",
      "22it [00:00, 132.53it/s]\n",
      "22it [00:00, 169.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:11<00:00,  2.24s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 640.70it/s]\n",
      "22it [00:00, 49.90it/s]\n",
      "22it [00:00, 131.04it/s]\n",
      "22it [00:00, 170.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:20<00:00,  2.53s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 623.54it/s]\n",
      "22it [00:00, 49.91it/s]\n",
      "22it [00:00, 129.28it/s]\n",
      "22it [00:00, 168.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:08<00:00,  2.15s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 649.63it/s]\n",
      "22it [00:00, 49.88it/s]\n",
      "22it [00:00, 130.51it/s]\n",
      "22it [00:00, 167.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:25<00:00,  2.67s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 633.72it/s]\n",
      "22it [00:00, 50.10it/s]\n",
      "22it [00:00, 131.89it/s]\n",
      "22it [00:00, 166.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:32<00:00,  2.88s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 648.29it/s]\n",
      "22it [00:00, 50.32it/s]\n",
      "22it [00:00, 131.20it/s]\n",
      "22it [00:00, 169.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:24<00:00,  2.63s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 630.36it/s]\n",
      "22it [00:00, 50.55it/s]\n",
      "22it [00:00, 129.00it/s]\n",
      "22it [00:00, 167.15it/s]\n",
      " 44%|█████████████████████████████████████████████████████████▊                                                                          | 14/32 [00:18<00:28,  1.56s/it]"
     ]
    }
   ],
   "source": [
    "for seed in seeds:\n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "    # Create Pandas DataFrame\n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "    # Process the filted TC list in the config file\n",
    "    TC_tofilt_list = ast.literal_eval(config_set['TCfilt'])\n",
    "    # Get the names of the remaining TCs\n",
    "    filt_TClist = read_vars.remove_storms(trackpath=config_set['track_path'],\n",
    "                                          basinID=config_set['basin'],\n",
    "                                          yearmin=int(config_set['start_year']),\n",
    "                                          yearmax=int(config_set['end_year']),\n",
    "                                          remove_set=TC_tofilt_list\n",
    "                                         )\n",
    "    # Read saved SHIPS csvs\n",
    "    storeSHIPS = read_vars.read_SHIPS_csv(startyear=int(config_set['start_year']),\n",
    "                                          endyear=int(config_set['end_year']),\n",
    "                                          vars_path=config_set['vars_path'],\n",
    "                                          filted_TCnames=filt_TClist,suffixlist=['newships_dev_POT']\n",
    "                                         )\n",
    "    # Read selected variables from the pandas dfs\n",
    "    SHIPS_df = read_vars.create_SHIPS_df(startyear=int(config_set['start_year']),\n",
    "                                         endyear=int(config_set['end_year']),\n",
    "                                         SHIPSdict=storeSHIPS,\n",
    "                                         wantvarnames=config_set['SHIPSops_varname'],\n",
    "                                         targetname=target,\n",
    "                                         filted_TCnames=filt_TClist,\n",
    "                                         lagnum=int(config_set['target_lag']),\n",
    "                                         withshift='No',\n",
    "                                        )\n",
    "    # Add derived variables stored separately\n",
    "    store_dfstorms_ships = read_vars.add_derive_df(startyear=int(config_set['start_year']),\n",
    "                                                   endyear=int(config_set['end_year']),\n",
    "                                                   SHIPSdict=SHIPS_df,\n",
    "                                                   addfilepath='/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/SHIPS/ships_pkl/all_storms_ships23vars_obswmax.pkl',\n",
    "                                                   addvarname=['pc20'],\n",
    "                                                   filted_TCnames=filt_TClist,\n",
    "                                                   lagnum=int(config_set['target_lag']),\n",
    "                                                   withshift='No',\n",
    "                                                  )\n",
    "    \n",
    "    var_names=store_dfstorms_ships[2001]['ALLISON'].columns.values.tolist()\n",
    "    \n",
    "    TC_fulllist = {}\n",
    "    for year in np.linspace(int(config_set['start_year']),int(config_set['end_year']),int(config_set['end_year'])-int(config_set['start_year'])+1):\n",
    "        temp = store_dfstorms_ships[year]\n",
    "        for ind,name in enumerate(temp.keys()):\n",
    "            TC_fulllist[str(int(year))+'_'+name] = temp[name]\n",
    "            \n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "    # ML-ready dataset\n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "    # Split data with a 0.15 test, 0.15 valid split\n",
    "    datastorer = proc_dataset.splitdata_handler(df=TC_fulllist,\n",
    "                                                method='year',\n",
    "                                                seed=seed,\n",
    "                                                config=config_set,\n",
    "                                                testyears=[2020,2021]\n",
    "                                               )\n",
    "    # Remove empty storms in the data\n",
    "    traincleaned = {key: datastorer['train'][key] for ind,key in enumerate(datastorer['train'].keys()) if datastorer['train'][key].shape[0]>0}\n",
    "    validcleaned = {key: datastorer['valid'][key] for ind,key in enumerate(datastorer['valid'].keys()) if datastorer['valid'][key].shape[0]>0}\n",
    "    testcleaned = {key: datastorer['test'][key] for ind,key in enumerate(datastorer['test'].keys()) if datastorer['test'][key].shape[0]>0}\n",
    "    \n",
    "    # Replace original training data with the cleaned version\n",
    "    datastorer_n = deepcopy(datastorer)\n",
    "    \n",
    "    # Replace\n",
    "    datastorer_n['train'] = traincleaned\n",
    "    datastorer_n['valid'] = validcleaned\n",
    "    datastorer_n['test'] = testcleaned\n",
    "\n",
    "    # Get smoothed MSLP data and argmin values\n",
    "    smoothed_MSLP, MSLP_argmin = proc_dataset.proc_data(df=datastorer_n,\n",
    "                                                    seed=seed).smooth_and_minindices(varname='MSLP',sigma=3)\n",
    "    # Aligned the inputs with the minimum SLP data\n",
    "    aligned_train = proc_dataset.proc_data(df=datastorer_n,seed=seed).do_data_align(datastorer_n['train'],MSLP_argmin['train'],var_names)\n",
    "    aligned_valid = proc_dataset.proc_data(df=datastorer_n,seed=seed).do_data_align(datastorer_n['valid'],MSLP_argmin['valid'],var_names)\n",
    "    aligned_test = proc_dataset.proc_data(df=datastorer_n,seed=seed).do_data_align(datastorer_n['test'],MSLP_argmin['test'],var_names)\n",
    "    \n",
    "    # Combine different TCs into a long dataset\n",
    "    X,y,size = proc_dataset.df_proc_separate(aligned_train,aligned_valid,aligned_test,target)\n",
    "\n",
    "    # Find the mean and std of the training set for normalization\n",
    "    trainmean,trainstd = X['train'].dropna().mean(axis=0),X['train'].dropna().std(axis=0)\n",
    "\n",
    "    # Data normalization\n",
    "    Xnorml = proc_dataset.normalized_TCs_handler(train=aligned_train,\n",
    "                                                 valid=aligned_valid,\n",
    "                                                 test=aligned_test,\n",
    "                                                 trainmean=trainmean,\n",
    "                                                 trainstd=trainstd,\n",
    "                                                 dropcol=[target],\n",
    "                                                 target=target\n",
    "                                                )\n",
    "    var_names = Xnorml['train'][list(Xnorml['train'].keys())[0]].columns\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "    # Causal\n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "    onlyships_lag = causal_settings.link_onlyships(numvar=aligned_train[list(aligned_train.keys())[0]].shape[1],\n",
    "                                                   lag=int(config_set['target_lag']),\n",
    "                                                   target_ind=[0]\n",
    "                                                  )\n",
    "\n",
    "    results = []\n",
    "    for pc_alpha in tqdm([0.0001, 0.00015 ,0.001,0.0015,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,\n",
    "                          0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.86,0.88,0.9]):\n",
    "        Xnorml_c = {'train': {ind: np.asarray(Xnorml['train'][key].replace(np.nan,-999.0)) for ind,key in enumerate(Xnorml['train'].keys())},\n",
    "                    'valid': {ind: np.asarray(Xnorml['valid'][key].replace(np.nan,-999.0)) for ind,key in enumerate(Xnorml['valid'].keys())},\n",
    "                    'test': {ind: np.asarray(Xnorml['test'][key].replace(np.nan,-999.0)) for ind,key in enumerate(Xnorml['test'].keys())}\n",
    "                   }\n",
    "        result = train_PC1.Pipeline(Xnorml_c['train'],\n",
    "                                    pc_alpha,\n",
    "                                    pc_type='run_pcstable',\n",
    "                                    tau_min0=int(config_set['tau_min']),\n",
    "                                    tau_max0=int(config_set['tau_max']),\n",
    "                                    var_name=var_names,\n",
    "                                    link_assumptions=onlyships_lag).run_tigramite()\n",
    "        del Xnorml_c\n",
    "        gc.collect()\n",
    "        results.append(result)\n",
    "    \n",
    "    savetos = {'dataframes':Xnorml,'PC1_results':results,'var_names':var_names}\n",
    "    with open('../2024_causalML_results/results/'+str(int(config_set['target_lag']))+'_tmin0/'+\\\n",
    "              'SHIPSonly_causal/'+'results_seed'+str(int(seed))+'.pkl','wb') as handler:\n",
    "        pickle.dump(savetos,handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b02932-8dc3-49da-b3ee-0a1e3b1d86f7",
   "metadata": {},
   "source": [
    "# Performance Skill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f412558-201f-4175-be0b-d49e39d46970",
   "metadata": {},
   "source": [
    "## No causally-informed feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1392a6ae-e1db-4a2b-9ab2-d08b26dfa350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ytrain = np.concatenate([np.asarray(Xnorml['train'][key].dropna()[target]) for key in Xnorml['train'].keys()],axis=0)\n",
    "Xtrain = np.concatenate([np.asarray(Xnorml['train'][key].dropna().drop(columns=[target])) for key in Xnorml['train'].keys()],axis=0)\n",
    "yvalid = np.concatenate([np.asarray(Xnorml['valid'][key].dropna()[target]) for key in Xnorml['valid'].keys()],axis=0)\n",
    "Xvalid = np.concatenate([np.asarray(Xnorml['valid'][key].dropna().drop(columns=[target])) for key in Xnorml['valid'].keys()],axis=0)\n",
    "ytest = np.concatenate([np.asarray(Xnorml['test'][key].dropna()[target]) for key in Xnorml['test'].keys()],axis=0)\n",
    "Xtest = np.concatenate([np.asarray(Xnorml['test'][key].dropna().drop(columns=[target])) for key in Xnorml['test'].keys()],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eefa5ad-e8f3-4a43-8c20-e2afed4dc245",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Xnorml_nocausal \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mXtrain\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m: Xvalid, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: Xtest}\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: ytrain, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m: yvalid, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: ytest}\n\u001b[1;32m      3\u001b[0m regr \u001b[38;5;241m=\u001b[39m train_baseline\u001b[38;5;241m.\u001b[39mtrain_baseline_MLR(Xnorml_nocausal,y)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "Xnorml_nocausal = {'train': Xtrain, 'valid': Xvalid, 'test': Xtest}\n",
    "y = {'train': ytrain, 'valid': yvalid, 'test': ytest}\n",
    "regr = train_baseline.train_baseline_MLR(Xnorml_nocausal,y)\n",
    "\n",
    "MLR_scoreboard = performance_scores.scoreboard(regr).store_scores(Xnorml_nocausal,y)\n",
    "MLR_scoreboard['train']['r2'],MLR_scoreboard['valid']['r2'],MLR_scoreboard['test']['r2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d8992-9e5e-46c5-a48f-942bb0979ed8",
   "metadata": {},
   "source": [
    "## With causally-informed feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50bd52b4-ecd8-4936-bb1b-385a9b6b4e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_causal(PC1_results=None,Xnorml=None):\n",
    "    causal_predictor_list = [var_names[i] for i in [obj[0] for obj in PC1_results[0]]]\n",
    "    while target in causal_predictor_list: \n",
    "        causal_predictor_list.remove(target)\n",
    "        \n",
    "    Xtrain_causal = np.concatenate([np.asarray(Xnorml['train'][key].dropna()[causal_predictor_list]) for key in Xnorml['train'].keys()],axis=0)\n",
    "    Xvalid_causal = np.concatenate([np.asarray(Xnorml['valid'][key].dropna()[causal_predictor_list]) for key in Xnorml['valid'].keys()],axis=0)\n",
    "    Xtest_causal = np.concatenate([np.asarray(Xnorml['test'][key].dropna()[causal_predictor_list]) for key in Xnorml['test'].keys()],axis=0)\n",
    "    \n",
    "    Xnorml_causal = {'train': Xtrain_causal, 'valid': Xvalid_causal, 'test': Xtest_causal}\n",
    "    regr_causal = train_baseline.train_baseline_MLR(Xnorml_causal,y)\n",
    "    return performance_scores.scoreboard(regr_causal).store_scores(Xnorml_causal,y),Xnorml_causal,regr_causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9afd476-e3cb-4c33-bcdc-cbfa0a952ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores,Xs,regr = [],[],[]\n",
    "for obj in results:\n",
    "    score,X,regrz = benchmark_causal(PC1_results=obj,Xnorml=Xnorml)\n",
    "    scores.append(score)\n",
    "    Xs.append(X)\n",
    "    regr.append(regrz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcf6504b-7b44-4f04-8342-e19da58d8e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1021555358079308,\n",
       " 0.1021555358079308,\n",
       " 0.1021555358079308,\n",
       " 0.1021555358079308,\n",
       " 0.2452320855925929,\n",
       " 0.2452320855925929,\n",
       " 0.24405800371330577,\n",
       " 0.24379775741868182,\n",
       " 0.24379775741868182,\n",
       " 0.24379775741868182,\n",
       " 0.2446481135565478,\n",
       " 0.2709626786485583,\n",
       " 0.2709626786485583,\n",
       " 0.268247385815237,\n",
       " 0.2853524218899478,\n",
       " 0.28628801845663976,\n",
       " 0.28628801845663976,\n",
       " 0.28628801845663976,\n",
       " 0.28628801845663976,\n",
       " 0.28628801845663976,\n",
       " 0.28628801845663976,\n",
       " 0.28628801845663976,\n",
       " 0.28863877427561013,\n",
       " 0.28863877427561013,\n",
       " 0.28863877427561013,\n",
       " 0.28863877427561013,\n",
       " 0.2744416432922989,\n",
       " 0.28155526779540596,\n",
       " 0.28448719302397096,\n",
       " 0.28448719302397096,\n",
       " 0.28448719302397096,\n",
       " 0.292464581726671]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[obj['valid']['r2'] for obj in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a01c727a-76aa-48ad-93ff-d5a209f2d033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009977204607032775,\n",
       " 0.009977204607032775,\n",
       " 0.009977204607032775,\n",
       " 0.009977204607032775,\n",
       " 0.2716924929790153,\n",
       " 0.2716924929790153,\n",
       " 0.2750141812017797,\n",
       " 0.27450444848794664,\n",
       " 0.27450444848794664,\n",
       " 0.27450444848794664,\n",
       " 0.27774375521667305,\n",
       " 0.27871858308850184,\n",
       " 0.27871858308850184,\n",
       " 0.28418523034269094,\n",
       " 0.29524352448890256,\n",
       " 0.2973222397860653,\n",
       " 0.2973222397860653,\n",
       " 0.2973222397860653,\n",
       " 0.2973222397860653,\n",
       " 0.2973222397860653,\n",
       " 0.2973222397860653,\n",
       " 0.2973222397860653,\n",
       " 0.2944053005698549,\n",
       " 0.2944053005698549,\n",
       " 0.2944053005698549,\n",
       " 0.2944053005698549,\n",
       " 0.28052070333758905,\n",
       " 0.2981138735772464,\n",
       " 0.30615659889086966,\n",
       " 0.30615659889086966,\n",
       " 0.30615659889086966,\n",
       " 0.3178415691993145]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[obj['test']['r2'] for obj in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80e555-fec8-4a7a-82fa-69e568031559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
